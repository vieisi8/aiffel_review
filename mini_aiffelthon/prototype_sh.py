from fastapi import FastAPI, Request, HTTPException, File, UploadFile
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from PIL import Image
import io
import sqlite3
import tensorflow as tf
from tensorflow import keras
from keras.preprocessing.image import load_img, img_to_array
import numpy as np
import time
import requests
import urllib.parse
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_ollama import OllamaLLM


# Create FastAPI instance
app = FastAPI()

# Jinja2 í…œí”Œë¦¿ ì„¤ì •
templates = Jinja2Templates(directory="/content/drive/MyDrive/Colab Notebooks/caloriecheck_exp_á„á…©á„ƒá…³á„‘á…¡á„‹á…µá†¯/prototype fast_api/templates")


@app.get("/")
async def home(request: Request):
    return templates.TemplateResponse("index.html",{"request":request})


@app.post("/predict")
async def predict_image(file: UploadFile = File(...)):
    try:
        # íŒŒì¼ ì½ê¸° ë° Pillowë¡œ ì´ë¯¸ì§€ ì—´ê¸°
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))

        image.save("/content/drive/MyDrive/Colab Notebooks/caloriecheck_exp_á„á…©á„ƒá…³á„‘á…¡á„‹á…µá†¯/prototype fast_api/image.png")

        model_path = '/content/drive/MyDrive/data/results_dam/models/cnn_text_extraction_model_5.h5'
        model = keras.models.load_model(model_path)

        class_labels = ['65373', '65703', '65746', '66011', '66300',
                        '70034', '70037', '70051', '70061', '70101',
                        '70211', '70212', '75022', '80002', '80008',
                        '80063', '85031', '90029', '90057', '90113']
        name_index = {
            '65373': 'ìŠˆê°€ë²„ë¸”ê³¼íƒ„ì‚°ì†Œë‹¤',
            '65703': 'ë†ì‹¬ ë°±ì‚°ìˆ˜',
            '65746': 'ë¸ëª¬íŠ¸ì˜¤ë Œì§€ë“œë§í¬', #1
            '66011': 'ì•„ì„ì–¼ë¼ì´ë¸Œ ìœ ê¸°ë† ì½¤ë¶€ì°¨',
            '66300': 'ë§¤ì¼ ìƒí•˜ëª©ì¥ ìœ ê¸°ë† ì£¼ìŠ¤',
            '70034': 'ê°€ì•¼í† ë§ˆí† ë†ì¥', #2
            '70037': 'ë­ê±°ìŠ¤ ì˜¤ë Œì§€',
            '70051': 'ê´‘ë™ ì•¼ê´€ë¬¸ ì•¼ì™•', # 'ê´‘ë™ ì•½ê³¼ë¬¸', # ê´‘ë™ì•¼ê´€ë¬¸ì•¼ì™•
            '70061': 'ì½”ì¹´ ìŠ¤í”„ë¼ì´íŠ¸',
            '70101': 'ì˜¤ì¼€ì´ ì—í”„ ì•„ì¿ ì•„',
            '70211': 'íŒŒìŠ¤í‡´ë¥´ ì•¼ì±„ë†ì¥',
            '70212': 'íŒŒìŠ¤í‡´ë¥´ ABC ì£¼ìŠ¤',
            '75022': 'ì¼í™” ì´ˆì • ë ˆëª¬',
            '80002': 'ë¡¯ë°ìœ ê¸°ë†ì•¼ì±„ê³¼ì¼', #3
            '80008': 'íŒŒìŠ¤í‡´ë¥´ì˜¤ê°€ë‹‰ìœ ê¸°ë†ì‚¬ê³¼ë‹¹ê·¼', #4
            '80063': 'ìì—°ì€ìš”ê±°ìƒí¼ë³µìˆ­ì•„',
            '85031': 'ë³´í•´ ì–‘ì¡° ë¶€ë¼ë” ì†Œë‹¤',
            '90029': 'ë¹™ê·¸ë ˆë”°ì˜´ë°±ìëª½í¬ë©œë¡œ', # 5
            '90057': 'ì¼í™” íƒ‘ì”¨ í¬ë„',
            '90113': 'íŒ”ë„ë¹„ë½ì‹í˜œ' #6
        }
        label_index = {
            '65373': 0,
            '65703': 1,
            '65746': 2,
            '66011': 3,
            '66300': 4,
            '70034': 5,
            '70037': 6,
            '70051': 7,
            '70061': 8,
            '70101': 9,
            '70211': 10,
            '70212': 11,
            '75022': 12,
            '80002': 13,
            '80008': 14,
            '80063': 15,
            '85031': 16,
            '90029': 17,
            '90057': 18,
            '90113': 19
        }
        # ì˜ˆì¸¡ í•¨ìˆ˜
        def predict_text_from_image(image_path, model, label_index, name_index):
          img = load_img(image_path, target_size=(64, 64))  # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
          img_array = img_to_array(img) / 255.0  # ì •ê·œí™”
          img_array = np.expand_dims(img_array, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
          predictions = model.predict(img_array)
          predicted_class = np.argmax(predictions)  # ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ë²ˆí˜¸
          predicted_key = class_labels[predicted_class]  # í´ë˜ìŠ¤ ë²ˆí˜¸ë¥¼ keyë¡œ ë³€í™˜
          predicted_name = name_index.get(predicted_key, "Unknown")  # keyë¥¼ í†µí•´ í•œê¸€ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
          return predicted_name

        # LLM ì„¤ì •
        llm = OllamaLLM(model='EEVE-Korean-10.8B:latest')

        # ë„¤ì´ë²„ ë¸”ë¡œê·¸ API ê²€ìƒ‰ í•¨ìˆ˜
        def naver_blog_search(query, client_id, client_secret, display=10):
            enc_query = urllib.parse.quote(query)
            url = f"https://openapi.naver.com/v1/search/blog.json?query={enc_query}&display={display}&start=1&sort=sim"
            headers = {
                'X-Naver-Client-Id': client_id,
                'X-Naver-Client-Secret': client_secret
            }
            response = requests.get(url, headers=headers)
            if response.status_code == 200:
                return response.json()
            else:
                raise Exception(f"API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}, {response.text}")

        # ê´‘ê³ ì„± ê²°ê³¼ í•„í„°ë§ í•¨ìˆ˜
        def filter_advertisements(data, ad_keywords):
            filtered_items = [
                item for item in data['items']
                if not any(keyword in (item['title'] + item['description']) for keyword in ad_keywords)
            ]
            return {"items": filtered_items}

        # ê²€ìƒ‰ ê²°ê³¼ í¬ë§· í•¨ìˆ˜
        def format_blog_results(data):
            docs = []
            for item in data['items']:
                # HTML íƒœê·¸ ì œê±°
                title = item['title'].replace("<b>", "").replace("</b>", "")
                description = item['description'].replace("<b>", "").replace("</b>", "")
                docs.append(f"ì œëª©: {title}\nìš”ì•½: {description}\në¸”ë¡œê·¸ ë§í¬: {item['link']}\n")
            return "\n\n".join(docs)

        # ChatPrompt ì„¤ì •
        prompt = ChatPromptTemplate.from_template(
            ':\n{context}\n\nìœ„ í›„ê¸°ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ "{question}"ì— ëŒ€í•œ í•µì‹¬ì„ í•œì¤„ë¡œ ìš”ì•½í•´ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”.'
        )

        # LangChain ì‹¤í–‰ ì²´ì¸
        def create_chain():
            chain = (
                prompt
                | llm
                | StrOutputParser()
            )
            return chain

        # ë„¤ì´ë²„ ë¸”ë¡œê·¸ API ê²€ìƒ‰ ì‹¤í–‰ ë° ìš”ì•½ ì‘ì—…
        def run_query(predicted_label, client_id, client_secret, ad_keywords):
            # ì˜ˆì¸¡ëœ ë¼ë²¨ì„ ì¿¼ë¦¬ë¡œ ì‚¬ìš©
            query = predicted_label + " ìŒë£Œìˆ˜ ë§› í›„ê¸°"

            # API í˜¸ì¶œ
            start_time_api = time.time()
            results = naver_blog_search(query, client_id, client_secret)
            end_time_api = time.time()

            # ê´‘ê³ ì„± ê²°ê³¼ í•„í„°ë§
            filtered_results = filter_advertisements(results, ad_keywords)

            # ì •ì œëœ ë°ì´í„°ë¥¼ í¬ë§·íŒ…
            formatted_context = format_blog_results(filtered_results)

            # LangChain ì‹¤í–‰
            chain = create_chain()
            start_time_llm = time.time()
            inputs = {
                "context": formatted_context,
                "question": f"{query}ì˜ ë§›ì— ëŒ€í•´ í•œì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”."
            }
            summary = chain.invoke(inputs)
            end_time_llm = time.time()

            # ì‹œê°„ ì¶œë ¥
            print(f"API í˜¸ì¶œ ì†Œìš” ì‹œê°„: {end_time_api - start_time_api:.2f}ì´ˆ")
            print(f"LLM ì‹¤í–‰ ì†Œìš” ì‹œê°„: {end_time_llm - start_time_llm:.2f}ì´ˆ")

            # ìš”ì•½ ì¶œë ¥
            print("ê²€ìƒ‰ì–´ (Query):", query)
            print("ìš”ì•½ ê²°ê³¼:")
            print(summary)

            return summary

        def sql(predicted_label):
          conn = sqlite3.connect('/content/drive/MyDrive/Colab Notebooks/caloriecheck_exp_á„á…©á„ƒá…³á„‘á…¡á„‹á…µá†¯/Drink_DBv2 (1).db')
          cursor = conn.cursor()

          drink = predicted_label
          cursor.execute(f"SELECT * FROM Drink where ì‹í’ˆëª…=='{drink}'")
          row_count = cursor.fetchone()

          if row_count is None:
              result = {
                  "ì‹í’ˆëª…": None,
                  "ì œì¡°ì‚¬ëª…": None,
                  "ì˜ì–‘ì„±ë¶„í•¨ëŸ‰ê¸°ì¤€ëŸ‰": None,
                  "ì—ë„ˆì§€(kcal)": None,
                  "ë‹¨ë°±ì§ˆ(g)": None,
                  "ì§€ë°©(g)": None,
                  "íƒ„ìˆ˜í™”ë¬¼(g)": None,
                  "ë‹¹ë¥˜(g)": None,
                  "ë‚˜íŠ¸ë¥¨(mg)": None,
                  "ì½œë ˆìŠ¤í…Œë¡¤(mg)": None,
                  "í¬í™”ì§€ë°©ì‚°(g)": None,
                  "íŠ¸ëœìŠ¤ì§€ë°©ì‚°(g)": None,
                  "ì‹í’ˆì¤‘ëŸ‰": None,
                  "ì˜ˆì™¸": "ì•—!ğŸ˜¨ í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì— ê´€ë ¨ ìƒí’ˆì •ë³´ê°€ ì•„ì§ ë¶€ì¬í•©ë‹ˆë‹¤! ê³§ ë°˜ì˜í•˜ê² ìŠµë‹ˆë‹¤ğŸ«¡"
              }
          else:
              result = {
                  "ì‹í’ˆëª…": row_count[1],
                  "ì œì¡°ì‚¬ëª…": row_count[2],
                  "ì˜ì–‘ì„±ë¶„í•¨ëŸ‰ê¸°ì¤€ëŸ‰": row_count[3],
                  "ì—ë„ˆì§€(kcal)": row_count[4],
                  "ë‹¨ë°±ì§ˆ(g)": row_count[5],
                  "ì§€ë°©(g)": row_count[6],
                  "íƒ„ìˆ˜í™”ë¬¼(g)": row_count[7],
                  "ë‹¹ë¥˜(g)": row_count[8],
                  "ë‚˜íŠ¸ë¥¨(mg)": row_count[9],
                  "ì½œë ˆìŠ¤í…Œë¡¤(mg)": row_count[10],
                  "í¬í™”ì§€ë°©ì‚°(g)": row_count[11],
                  "íŠ¸ëœìŠ¤ì§€ë°©ì‚°(g)": row_count[12],
                  "ì‹í’ˆì¤‘ëŸ‰": row_count[13],
                  "ì˜ˆì™¸": None
              }

          return result

        # CNN ì˜ˆì¸¡ ë° ê²€ìƒ‰ ì‹¤í–‰
        def main():
            client_id = 'DrOoOca4OH52hHPEbBSX'
            client_secret = 'AjoAFgs_E_'
            ad_keywords = ["ê´‘ê³ ", "í˜‘ì°¬", "ì„œí¬í„°ì¦ˆ"]

            image_path = '/content/drive/MyDrive/Colab Notebooks/caloriecheck_exp_á„á…©á„ƒá…³á„‘á…¡á„‹á…µá†¯/prototype fast_api/image.png'

            # ì˜ˆì¸¡ í•¨ìˆ˜ ì‹¤í–‰
            predicted_label = predict_text_from_image(image_path, model, label_index, name_index)

            print(f"Predicted Label: {predicted_label}")

            # ì˜ˆì¸¡ëœ ë¼ë²¨ë¡œ ë¸”ë¡œê·¸ ê²€ìƒ‰ ì‹¤í–‰
            review = run_query(predicted_label, client_id, client_secret, ad_keywords)
            nutritional_properties = sql(predicted_label)

            return predicted_label, review, nutritional_properties

        # ì‹¤í–‰
        name, review, nutritional_properties = main()

        result={'name':name,
                'review':review,
                'nutritional_properties': nutritional_properties}

        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)